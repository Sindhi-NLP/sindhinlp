# Sindhi NLP

A package for Sindhi language processing including stopword removal, POS tagging, and lemmatization.

## Installation

### Clone the repository

```bash
git clone https://github.com/yourusername/sindhinlp.git
cd sindhinlp
```

### Install dependencies

Install the dependencies using pip:

```bash
pip install -r requirements.txt
```

### Install the package

Install the package in editable mode:

```bash
pip install -e .
```

## Usage

### Tokenization

#### Tokenize Words

```python
from sindhinlp.preprocess.tokenize import tokenize_words

text = "Ø³Ù†ÚŒÙŠ Ø²Ø¨Ø§Ù† Ø¬Ùˆ Ù…ÙˆÙ†Ú¾Ù†Ø¬Ùˆ Ø¹Ù„Ù…ØŒ ØªØ§Ø±ÙŠØ®."
word_tokens = tokenize_words(text)
print(word_tokens)
```

#### Tokenize Sentences

```python
from sindhinlp.preprocess.tokenize import tokenize_sentences

text = "Ø³Ù†ÚŒÙŠ Ø²Ø¨Ø§Ù† Ø¬Ùˆ Ù…ÙˆÙ†Ú¾Ù†Ø¬Ùˆ Ø¹Ù„Ù…ØŒ ØªØ§Ø±ÙŠØ® Û½ Ø«Ù‚Ø§ÙØª Û¾ Ø³Ù†ÚŒ Ø¬ÙŠ ÚŠÙˆÚªØ±ÙŠÙˆÙ†ØŒ Ù„ÙˆÚªÙŠÙˆÙ† Û½ ÚªØªØ§Ø¨ÙˆÙ† Û¾ Ø³Ù…Ø¬Ù‡Ø§ÙŠÙˆ Ø¬ÙŠÙˆÙ† ÚªØ±ØªÙˆØªÛ” Ø³Ù†ÚŒÙŠ Ø¬ÙŠ Ø¹ÙˆØ§Ù… Ú©ÙŠ Ø³Ù…Ø¬Ù‡Ø§Ú» Ø¬Ùˆ Ø±ÙˆÙŠØ§ Ù¾Ù†Ù‡Ù†Ø¬ÙŠ Ø²Ø¨Ø§Ù† Û¾ Ø³Ø§Ø¦Ù†Ø³ØŒ ÙÙ†ÙˆÙ† Û½ Ø³Ø§ÙŠÙ†Ø³ ÚªØ§Ù† Ù…ØªØ¹Ù„Ù‚ Ø§Ø­Ø§Ø·Ùˆ Ø³ÙˆØ§Ù†Ø­ Û½ ÚªØ±ØªÙˆØª Û½ Ù…Ø­Ø§ÙˆØ±Ù† Ø¬Ùˆ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯ÙŠÙ†Ø¯Ùˆ Ø¢Ù‡ÙŠ."
sentence_tokens = tokenize_sentences(text)
print(sentence_tokens)
```

#### Custom Tokenize

```python
from sindhinlp.preprocess.tokenize import custom_tokenize

text = "Ø³Ù†ÚŒÙŠ Ø²Ø¨Ø§Ù†ØŒ Ø¬ÙŠ Ù…ÙˆÙ†Ú¾Ù†Ø¬Ùˆ Ø¹Ù„Ù…ØŒ ØªØ§Ø±ÙŠØ® Û½ Ø«Ù‚Ø§ÙØª"
custom_tokens = custom_tokenize(text, "ØŒ")
print(custom_tokens)
```

### Stopwords

#### Get Stopwords

```python
from sindhinlp.preprocess.stopwords import get_stopwords

stopwords = get_stopwords()
print(stopwords)
```

#### Get Extended Stopwords

```python
from sindhinlp.preprocess.stopwords import get_extend_stopwords

extended_set = {'Ù†Ø¦ÙˆÙ†', 'Ø§Ø¶Ø§ÙÙŠ'}
extended_stopwords = get_extend_stopwords(extended_set)
print(extended_stopwords)
```

### Text Preprocessing

#### Remove Special Characters

```python
from sindhinlp.preprocess.text_preprocessing import remove_special_characters

text = "Ø³Ù†ÚŒÙŠ Ø²Ø¨Ø§Ù† Ø¬Ùˆ Ù…ÙˆÙ†Ú¾Ù†Ø¬Ùˆ Ø¹Ù„Ù…ØŒ ØªØ§Ø±ÙŠØ® Û½ Ø«Ù‚Ø§ÙØªÛ” ÚªØªØ§Ø¨ Ø¬Ùˆ Ø¹Ù†ÙˆØ§Ù†: 'Ø³Ù†ÚŒ Ø¬Ùˆ Ø§Ù“Ø³Ù…Ø§Ù†'"
clean_text = remove_special_characters(text)
print(clean_text)
```

#### Remove Stopwords

```python
from sindhinlp.preprocess.text_preprocessing import remove_stopwords

text = "Ù…Ø­Ø§ÙˆØ±Ù† Ø¬Ùˆ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯ÙŠÙ†Ø¯Ùˆ Ø¢Ù‡ÙŠ"
stopword_removed_text = remove_stopwords(text)
print(stopword_removed_text)
```

#### Remove Numbers

```python
from sindhinlp.preprocess.text_preprocessing import remove_number

text = "Ù‡ÙŠ 1234 Ù½ÙŠØ³Ù½ 5678 Ù…ÙˆØ§Ø¯ Ø¢Ù‡ÙŠ 90 Ù†Ù…Ø¨Ø± Ø¬ÙŠ ÙˆÚ† Û¾."
result = remove_number(text)
print(result)
```

#### Remove URLs

```python
from sindhinlp.preprocess.text_preprocessing import remove_urls

text = "Ú¾ÙŠ Ù„Ù†Úª Ú†ÙŠÚª ÚªØ±ÙŠÙˆ: http://example.com Û½ Ù¾Ú» ÙˆØ²Ù½ ÚªØ±ÙŠÙˆ https://www.example.org ÙˆÚŒÙŠÚª Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„Ø§Ø¡Ù."
result = remove_urls(text)
print(result)
```

#### Remove Emojis

```python
from sindhinlp.preprocess.text_preprocessing import remove_emoji

text = "Ú¾ÙŠ Ù½ÙŠØ³Ù½ Ù…ÙˆØ§Ø¯ Ø¢Ú¾ÙŠ ğŸ˜ŠğŸš€ğŸŒŸ Ø¬ÙŠ ÙˆÚ† Û¾."
result = remove_emoji(text)
print(result)
```

### Lemmatization

```python
from sindhinlp.preprocess.lematize import lemmatize

word = "Ø±Ù‡Ù†Ø¯Ùˆ"
lemma = lemmatize(word)
print(lemma)
```

### POS Tagging

```python
from sindhinlp.models.pos_tagging import pos_tags

sentence = "Ù…ÙˆØ³Ù… Ø¨Ù‡ØªØ±ÙŠÙ† Ø¢Ù‡ÙŠ."
tags = pos_tags(sentence)
print(tags)
```

### Load Dataset

```python
from sindhinlp.data.load_data import load_dataset

# Load default dataset
df = load_dataset()
print(df.head())

# Load specific dataset
df = load_dataset('article_dataset')
print(df.head())
```

## Running Tests

To run tests, use the following command:

```bash
python -m unittest discover -s test
```

## Contributing

We welcome contributions to this project! To contribute, please follow the steps mentioned in [CONTRIBUTING](CONTRIBUTING.md)


## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE.md) file for details.
